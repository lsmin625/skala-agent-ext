from langchain_core.prompts import ChatPromptTemplate
from quiz_agents.models import FinalReport
from quiz_agents.nodes.state import AppState
from quiz_agents.services.loaders import load_quizzes
from quiz_agents.services.llm import llm_with_final_report


def quiz_setter(state: AppState) -> AppState:
    """í€´ì¦ˆ ë¬¸í•­ ì„¤ì •"""
    questions = load_quizzes()
    if not questions:
        return {
            "chat_history": [(
                "assistant",
                "í€´ì¦ˆë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆê±°ë‚˜ í’€ ìˆ˜ ìˆëŠ” ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤."
            )],
            "questions": [],
        }
    return {
        "questions": questions,
        "quiz_index": 0,
        "user_answers": [],
        "final_report": None,
        "chat_history": [(
            "assistant",
            f"í€´ì¦ˆë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ì´ {len(questions)}ë¬¸í•­ì…ë‹ˆë‹¤."
        )],
    }

def continue_quiz_condition(state: AppState) -> str:
    """í€´ì¦ˆ ê³„ì†/ì±„ì  ë¶„ê¸° í‚¤ ì¼ì¹˜"""
    questions = state.get("questions", [])
    quiz_index = state.get("quiz_index", 0)
    if quiz_index < len(questions):
        return "continue_quiz"
    else:
        return "grade_quiz"

def quiz_popper(state: AppState) -> AppState:
    """í˜„ì¬ ë¬¸ì œ ì¶œë ¥"""
    quiz_index = state["quiz_index"]
    quiz = state["questions"][quiz_index]
    text = f"ë¬¸ì œ {quiz_index + 1}: {quiz['question']}"
    if quiz["type"] == "multiple_choice":
        choices = [f"{i + 1}. {c}" for i, c in enumerate(quiz["choices"])]
        text += "\n" + "\n".join(choices)
    return {"chat_history": [("assistant", text)]}

def answer_collector(state: AppState) -> AppState:
    """ë‹µë³€ ìˆ˜ì§‘ ë° ë‹¤ìŒ ì¸ë±ìŠ¤"""
    quiz_index = state.get("quiz_index", 0)
    quiz = state.get("questions", [])[quiz_index]
    user_input = state.get("user_input", "").strip()
    user_answers = state.get("user_answers", [])

    if not user_input:
        return {"chat_history": [("assistant", "ë‹µë³€ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")]}
    processed_answer = user_input
    if quiz["type"] == "multiple_choice":
        try:
            sel = int(user_input) - 1
            if 0 <= sel < len(quiz["choices"]):
                processed_answer = quiz["choices"][sel]
        except (ValueError, IndexError):
            pass

    user_answers.append(processed_answer)
    return {"user_answers": user_answers, "quiz_index": quiz_index + 1}

def grading_prompter(state: AppState) -> AppState:
    """ì±„ì  í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    questions = state.get("questions", [])
    user_answers = state.get("user_answers", [])

    prompt_buff = ["ì§€ê¸ˆë¶€í„° ì•„ë˜ì˜ ë¬¸ì œì™€ ì •ë‹µ, ê·¸ë¦¬ê³  ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë³´ê³  ì±„ì ì„ ì‹œì‘í•´ì£¼ì„¸ìš”."]
    for i, (q, a) in enumerate(zip(questions, user_answers)):
        prompt_buff.append(f"\n--- ë¬¸ì œ {i + 1} ---")
        prompt_buff.append(f"ë¬¸ì œ: {q['question']}")
        if q["type"] == "multiple_choice":
            prompt_buff.append(f"ì„ íƒì§€: {', '.join(q['choices'])}")
        prompt_buff.append(f"ì •ë‹µ: {q['answer']}")
        prompt_buff.append(f"ì‚¬ìš©ì ë‹µë³€: {a}")

    return {
        "chat_history": [("assistant", "ì±„ì ì„ ì§„í–‰í•©ë‹ˆë‹¤...")],
        "grading_prompt": "\n".join(prompt_buff),
    }

def grade_reporter(state: AppState) -> AppState:
    """LLM ì±„ì  â†’ FinalReport íŒŒì‹±"""
    system_message = """
    ë‹¹ì‹ ì€ 'ëª…íƒì • ì½”ë‚œ' í€´ì¦ˆì˜ ì „ë¬¸ ì±„ì ê´€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì œ, ì •ë‹µ, ì‚¬ìš©ì ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ì±„ì í•´ì£¼ì„¸ìš”. 
    ê° ë¬¸ì œì— ëŒ€í•´ ì •ë‹µ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê³  ì¹œì ˆí•œ í•´ì„¤ì„ ë§ë¶™ì—¬ì£¼ì„¸ìš”. 
    ëª¨ë“  ì±„ì ì´ ëë‚˜ë©´, ë§ˆì§€ë§‰ì—ëŠ” 'ì´ì : X/Y' í˜•ì‹ìœ¼ë¡œ ìµœì¢… ì ìˆ˜ë¥¼ ë°˜ë“œì‹œ ìš”ì•½í•´ì„œ ë³´ì—¬ì¤˜ì•¼ í•©ë‹ˆë‹¤. 
    ë°˜ë“œì‹œ ì§€ì •ëœ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
    """
    prompt = ChatPromptTemplate.from_messages(
        [("system", system_message), ("human", "{grading_data}")]
    )
    try:
        chain = prompt | llm_with_final_report
        report = chain.invoke({"grading_data": state["grading_prompt"]})
        return {"final_report": report}
    except Exception as e:
        print(f"ì±„ì  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        error_report = FinalReport(results=[], total_score="ì±„ì  ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        return {"final_report": error_report}

def report_formatter(state: AppState) -> AppState:
    """FinalReport â†’ ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸"""
    final_report = state["final_report"]
    report_buff = ["ì±„ì ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰\n"]
    if final_report and final_report.results:
        for i, res in enumerate(final_report.results):
            is_correct_text = "âœ… ì •ë‹µ" if res.is_correct else "âŒ ì˜¤ë‹µ"
            report_buff.append(f"--- ë¬¸ì œ {i + 1} ---")
            report_buff.append(f"ë¬¸ì œ: {res.question}")
            report_buff.append(f"ì •ë‹µ: {res.correct_answer}")
            report_buff.append(f"ì œì¶œí•œ ë‹µë³€: {res.user_answer}")
            report_buff.append(f"ê²°ê³¼: {is_correct_text}")
            report_buff.append(f"í•´ì„¤: {res.explanation}\n")
        report_buff.append(f"**{final_report.total_score}**")
    else:
        report_buff.append("ì±„ì  ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    report_buff.append("\ní€´ì¦ˆë¥¼ ë‹¤ì‹œ ì‹œì‘í•˜ë ¤ë©´ 'í€´ì¦ˆ ì‹œì‘'ì´ë¼ê³  ì…ë ¥í•´ì£¼ì„¸ìš”.")
    return {"chat_history": [("assistant", "\n".join(report_buff))]}

